{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install openai langchain langchain-openai langchain-community faiss-cpu requests beautifulsoup4 pandas tqdm --quiet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport re\nimport urllib3\nfrom openai import OpenAI, AuthenticationError\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\nfrom tqdm import tqdm\nimport gradio as gr\nfrom kaggle_secrets import UserSecretsClient\n\n# Disable SSL warnings for expired certificate\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n\n# Set OpenAI API key from Kaggle Secrets\ntry:\n    user_secrets = UserSecretsClient()\n    os.environ[\"OPENAI_API_KEY\"] = user_secrets.get_secret(\"OPENAI_API_KEY\")\nexcept Exception as e:\n    raise ValueError(f\"Failed to load OPENAI_API_KEY from Kaggle Secrets: {str(e)}. Please ensure the secret is set.\")\n\n# Verify API key\nif not os.environ.get(\"OPENAI_API_KEY\"):\n    raise ValueError(\"OPENAI_API_KEY is not set. Please configure it in Kaggle Secrets.\")\n\n# Initialize OpenAI client\nclient = OpenAI()\ntry:\n    client.models.list()  # Test API key validity\n    print(\"✅ OpenAI API key validated successfully.\")\nexcept AuthenticationError as e:\n    raise AuthenticationError(f\"OpenAI authentication failed: {str(e)}. Please check your API key in Kaggle Secrets.\")\n\nPPC_URL = \"https://www.pakistani.org/pakistan/legislation/1860/actXLVof1860.html\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport re\nimport urllib3\n\n# Disable SSL warnings for expired certificate\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n\nPPC_URL = \"https://www.pakistani.org/pakistan/legislation/1860/actXLVof1860.html\"\n\ndef scrape_ppc_full_advanced():\n    resp = requests.get(PPC_URL, verify=False)\n    soup = BeautifulSoup(resp.text, \"html.parser\")\n\n    # Get raw text only from main content area\n    raw_text = soup.get_text(separator=\"\\n\")\n    raw_text = re.sub(r'\\n+', '\\n', raw_text).strip()\n\n    # Cut everything before main title and after appendix/footer\n    start_idx = raw_text.lower().find(\"pakistan penal code\")\n    end_idx = raw_text.lower().rfind(\"schedule\")\n    main_text = raw_text[start_idx:end_idx].strip()\n\n    # Split into lines\n    lines = [line.strip() for line in main_text.split(\"\\n\") if line.strip()]\n\n    data = []\n    current_chapter = \"\"\n    current_section = \"\"\n    current_text = []\n\n    def save_section():\n        if current_section and current_text:\n            data.append({\n                \"id\": f\"PPC_{current_section}\",\n                \"chapter\": current_chapter,\n                \"source\": \"PPC\",\n                \"type\": \"article\",\n                \"language\": \"en\",\n                \"official_text\": \" \".join(current_text).strip(),\n                \"summary_text\": \"\"\n            })\n\n    for line in lines:\n        # Detect Chapter headings\n        if re.match(r'Chapter\\s+[A-Z0-9]+', line, re.IGNORECASE):\n            current_chapter = line\n            continue\n\n        # Detect Section numbers in multiple formats\n        sec_match = re.match(r'(Section|S\\.)\\s*(\\d+[A-Z]?)', line)\n        num_match = re.match(r'^(\\d+[A-Z]?)\\.', line)  # e.g., \"375.\"\n        if sec_match or num_match:\n            save_section()\n            current_section = sec_match.group(2) if sec_match else num_match.group(1)\n            current_text = [line]\n        else:\n            current_text.append(line)\n\n    # Save last section\n    save_section()\n\n    return pd.DataFrame(data)\n\nppc_df = scrape_ppc_full_advanced()\nprint(f\"Scraped {len(ppc_df)} PPC sections\")\nppc_df.head(10)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def summarize_text(text, lang=\"en\"):\n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-4o-mini\",\n            messages=[\n                {\"role\": \"system\", \"content\": f\"Summarize the following legal text in {lang.capitalize()}. Keep it concise (15-80 words).\"},\n                {\"role\": \"user\", \"content\": text[:2000]}  # Truncate to avoid token limits\n            ],\n            max_tokens=100,\n            temperature=0.3\n        )\n        return response.choices[0].message.content.strip()\n    except AuthenticationError as e:\n        raise AuthenticationError(f\"OpenAI authentication failed: {str(e)}\")\n    except Exception as e:\n        print(f\"Error summarizing text: {str(e)}\")\n        return f\"Summary failed due to API error: {str(e)}\"\n\nppc_df[\"summary_en\"] = \"\"\nppc_df[\"summary_ur\"] = \"\"\n\nbatch_size = 8\ntotal_batches = (len(ppc_df) + batch_size - 1) // batch_size\n\nfor i in tqdm(range(total_batches)):\n    start = i * batch_size\n    end = min(start + batch_size, len(ppc_df))\n    batch_texts = ppc_df.iloc[start:end][\"official_text\"].tolist()\n\n    try:\n        en_summaries = [summarize_text(text, \"en\") for text in batch_texts]\n        ur_summaries = [summarize_text(text, \"ur\") for text in batch_texts]\n    except Exception as e:\n        print(f\"Error in batch {i}: {str(e)}\")\n        en_summaries = [\"Error\" for _ in batch_texts]\n        ur_summaries = [\"Error\" for _ in batch_texts]\n\n    ppc_df.loc[start:end-1, \"summary_en\"] = en_summaries\n    ppc_df.loc[start:end-1, \"summary_ur\"] = ur_summaries\n\n    # Save partial checkpoint every 5 batches\n    if i % 5 == 0:\n        ppc_df.to_csv(\"ppc_bilingual_partial.csv\", index=False)\n\n# Final save\nppc_df.to_csv(\"ppc_bilingual.csv\", index=False)\nprint(\"✅ Saved bilingual PPC dataset as ppc_bilingual.csv\")\nppc_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Use combined English + Urdu summaries for embeddings\ntexts_for_index = (ppc_df[\"summary_en\"] + \" \" + ppc_df[\"summary_ur\"]).tolist()\nmetadatas = ppc_df.to_dict(orient=\"records\")\n\n# Initialize OpenAI embeddings\ntry:\n    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\nexcept AuthenticationError as e:\n    raise AuthenticationError(f\"Failed to initialize embeddings: {str(e)}\")\n\n# Create FAISS vector store with LangChain\nvectorstore = FAISS.from_texts(\n    texts=texts_for_index,\n    embedding=embeddings,\n    metadatas=metadatas\n)\n\n# Save the vector store\nvectorstore.save_local(\"ppc_faiss_index\")\nprint(f\"FAISS index built with {vectorstore.index.ntotal} entries.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the vector store\ntry:\n    vectorstore = FAISS.load_local(\"ppc_faiss_index\", embeddings=embeddings, allow_dangerous_deserialization=True)\nexcept Exception as e:\n    raise Exception(f\"Failed to load FAISS index: {str(e)}\")\n\n# Set up retriever\nretriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n\n# Initialize OpenAI LLM\ntry:\n    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\nexcept AuthenticationError as e:\n    raise AuthenticationError(f\"Failed to initialize LLM: {str(e)}\")\n\n# Define prompt template\nprompt = PromptTemplate.from_template(\"\"\"\nAnswer the question based on the following context from the Pakistan Penal Code:\n{context}\n\nQuestion: {question}\nAnswer in a clear, concise manner:\n\"\"\")\n\n# Build RAG chain\nrag_chain = (\n    {\"context\": retriever | (lambda docs: \"\\n\\n\".join([f\"Section {d.metadata['id']}: {d.page_content}\" for d in docs])),\n     \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n\n# Test the RAG chain\nquery = \"What is the punishment for theft in PPC?\"\nprint(\"Query:\", query)\ntry:\n    print(\"Answer:\", rag_chain.invoke(query))\nexcept Exception as e:\n    print(f\"Error during RAG query: {str(e)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def chatbot(query):\n    try:\n        return rag_chain.invoke(query)\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\ndemo = gr.Interface(\n    fn=chatbot,\n    inputs=gr.Textbox(lines=2, placeholder=\"Ask a question about PPC (in English or Urdu)...\"),\n    outputs=\"text\",\n    title=\"⚖️ PPC RAG Chatbot with OpenAI & LangChain\",\n    description=\"Powered by OpenAI for summarization/generation and LangChain for RAG. Supports bilingual queries.\"\n)\n\ndemo.launch(share=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}